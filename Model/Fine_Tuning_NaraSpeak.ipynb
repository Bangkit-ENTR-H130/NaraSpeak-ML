{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8738480,"sourceType":"datasetVersion","datasetId":5246186},{"sourceId":8738633,"sourceType":"datasetVersion","datasetId":5246305}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers datasets torch","metadata":{"execution":{"iopub.status.busy":"2024-06-20T13:19:23.721085Z","iopub.execute_input":"2024-06-20T13:19:23.721500Z","iopub.status.idle":"2024-06-20T13:19:37.154027Z","shell.execute_reply.started":"2024-06-20T13:19:23.721475Z","shell.execute_reply":"2024-06-20T13:19:37.153083Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.41.2)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.19.2)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (14.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets) (2024.3.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import T5ForConditionalGeneration, T5Tokenizer, AdamW\nimport pandas as pd\n","metadata":{"execution":{"iopub.status.busy":"2024-06-20T13:19:37.156078Z","iopub.execute_input":"2024-06-20T13:19:37.156386Z","iopub.status.idle":"2024-06-20T13:19:37.161372Z","shell.execute_reply.started":"2024-06-20T13:19:37.156358Z","shell.execute_reply":"2024-06-20T13:19:37.160508Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"model_name = \"pszemraj/flan-t5-large-grammar-synthesis\"\nmodel = T5ForConditionalGeneration.from_pretrained(model_name)\ntokenizer = T5Tokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-06-20T13:19:37.162621Z","iopub.execute_input":"2024-06-20T13:19:37.162970Z","iopub.status.idle":"2024-06-20T13:21:01.585795Z","shell.execute_reply.started":"2024-06-20T13:19:37.162939Z","shell.execute_reply":"2024-06-20T13:21:01.584848Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/892 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9cb2f27ba5df4711adef70553daa3bae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/3.13G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff96b1fc02a5428daaa8174680bc186b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.56k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00341e0058cc4b8daa0e933a42f24a32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce0b6850fb5249f3a1369ebf3264db1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"554f372b6e6949d49eac4d80d7ea0671"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70f2ac8ea9c947de891c975da4129c5f"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset_path=(\"/kaggle/input/clean-dataset/cleaned_data.csv\")\nimport csv\n\nwith open('/kaggle/input/clean-dataset/cleaned_data.csv', 'r', newline='', encoding='utf-8') as file_input, open('output.csv', 'w', newline='', encoding='utf-8') as file_output:\n    reader = csv.DictReader(file_input)\n    writer = csv.writer(file_output)\n\n    # Tulis header baru\n    writer.writerow(['incorrect', 'correct'])\n\n    # Proses setiap baris\n    for row in reader:\n        writer.writerow([row['incorrect'], row['correct']])\n","metadata":{"execution":{"iopub.status.busy":"2024-06-20T13:26:12.426793Z","iopub.execute_input":"2024-06-20T13:26:12.427753Z","iopub.status.idle":"2024-06-20T13:26:22.827932Z","shell.execute_reply.started":"2024-06-20T13:26:12.427714Z","shell.execute_reply":"2024-06-20T13:26:22.827149Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, input_max_len, target_max_len):\n        self.dataframe = dataframe\n        self.tokenizer = tokenizer\n        self.input_max_len = input_max_len\n        self.target_max_len = target_max_len\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, index):\n        source_text = self.dataframe.loc[index, 'incorrect']\n        target_text = self.dataframe.loc[index, 'correct']\n        \n        source = self.tokenizer(source_text, max_length=self.input_max_len, padding='max_length', truncation=True, return_tensors=\"pt\")\n        target = self.tokenizer(target_text, max_length=self.target_max_len, padding='max_length', truncation=True, return_tensors=\"pt\")\n        \n        source_ids = source['input_ids'].squeeze()\n        target_ids = target['input_ids'].squeeze()\n        \n        return {'input_ids': source_ids, 'attention_mask': source['attention_mask'].squeeze(), 'labels': target_ids}\n\n# Contoh penggunaan:\ndf = pd.read_csv(\"/kaggle/input/berish/Data_bersih.csv\", nrows=1000)\ndf.columns = [\"incorrect\", \"correct\"]\ndataset = CustomDataset(df, tokenizer, input_max_len=128, target_max_len=128)\ndataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-20T13:48:27.068256Z","iopub.execute_input":"2024-06-20T13:48:27.068630Z","iopub.status.idle":"2024-06-20T13:48:27.086422Z","shell.execute_reply.started":"2024-06-20T13:48:27.068601Z","shell.execute_reply":"2024-06-20T13:48:27.085547Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(), lr=5e-5)","metadata":{"execution":{"iopub.status.busy":"2024-06-20T13:48:30.438867Z","iopub.execute_input":"2024-06-20T13:48:30.439492Z","iopub.status.idle":"2024-06-20T13:48:30.451144Z","shell.execute_reply.started":"2024-06-20T13:48:30.439459Z","shell.execute_reply":"2024-06-20T13:48:30.450185Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"def train(model, dataloader, optimizer, device, epochs=3):\n    model.train()\n    model.to(device)\n    for epoch in range(epochs):\n        for batch_idx, batch in enumerate(dataloader):\n            optimizer.zero_grad()\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n            \n            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n            loss = outputs.loss\n            loss.backward()\n            optimizer.step()\n            \n            if batch_idx % 10 == 0:  # Print every 10 batches\n                print(f\"Epoch: {epoch+1}, Batch: {batch_idx}, Loss: {loss.item()}\")\n\ndevice = torch.device(\"cpu\")\ntrain(model, dataloader, optimizer, device)","metadata":{"execution":{"iopub.status.busy":"2024-06-20T13:48:30.857968Z","iopub.execute_input":"2024-06-20T13:48:30.858660Z","iopub.status.idle":"2024-06-20T18:27:49.225766Z","shell.execute_reply.started":"2024-06-20T13:48:30.858626Z","shell.execute_reply":"2024-06-20T18:27:49.224929Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Epoch: 1, Batch: 0, Loss: 0.08688411116600037\nEpoch: 1, Batch: 10, Loss: 0.04007495567202568\nEpoch: 1, Batch: 20, Loss: 0.23775027692317963\nEpoch: 1, Batch: 30, Loss: 0.09954997152090073\nEpoch: 1, Batch: 40, Loss: 0.08651918172836304\nEpoch: 1, Batch: 50, Loss: 0.07697045803070068\nEpoch: 1, Batch: 60, Loss: 0.057699255645275116\nEpoch: 1, Batch: 70, Loss: 0.11596230417490005\nEpoch: 1, Batch: 80, Loss: 0.0970078855752945\nEpoch: 1, Batch: 90, Loss: 0.09645769000053406\nEpoch: 1, Batch: 100, Loss: 0.04329666867852211\nEpoch: 1, Batch: 110, Loss: 0.03500140830874443\nEpoch: 1, Batch: 120, Loss: 0.1166069358587265\nEpoch: 1, Batch: 130, Loss: 0.022157881408929825\nEpoch: 1, Batch: 140, Loss: 0.1796889454126358\nEpoch: 1, Batch: 150, Loss: 0.051213495433330536\nEpoch: 1, Batch: 160, Loss: 0.18746241927146912\nEpoch: 1, Batch: 170, Loss: 0.09404228627681732\nEpoch: 1, Batch: 180, Loss: 0.09798043966293335\nEpoch: 1, Batch: 190, Loss: 0.15387089550495148\nEpoch: 1, Batch: 200, Loss: 0.03999416530132294\nEpoch: 1, Batch: 210, Loss: 0.07401920109987259\nEpoch: 1, Batch: 220, Loss: 0.13143569231033325\nEpoch: 1, Batch: 230, Loss: 0.0649794191122055\nEpoch: 1, Batch: 240, Loss: 0.09089888632297516\nEpoch: 2, Batch: 0, Loss: 0.1386149525642395\nEpoch: 2, Batch: 10, Loss: 0.01890602707862854\nEpoch: 2, Batch: 20, Loss: 0.04332466050982475\nEpoch: 2, Batch: 30, Loss: 0.048664696514606476\nEpoch: 2, Batch: 40, Loss: 0.0956348404288292\nEpoch: 2, Batch: 50, Loss: 0.040392711758613586\nEpoch: 2, Batch: 60, Loss: 0.06400993466377258\nEpoch: 2, Batch: 70, Loss: 0.03248311206698418\nEpoch: 2, Batch: 80, Loss: 0.08563968539237976\nEpoch: 2, Batch: 90, Loss: 0.1435437947511673\nEpoch: 2, Batch: 100, Loss: 0.07638188451528549\nEpoch: 2, Batch: 110, Loss: 0.08097239583730698\nEpoch: 2, Batch: 120, Loss: 0.100706547498703\nEpoch: 2, Batch: 130, Loss: 0.05021859332919121\nEpoch: 2, Batch: 140, Loss: 0.06829974055290222\nEpoch: 2, Batch: 150, Loss: 0.05933498591184616\nEpoch: 2, Batch: 160, Loss: 0.08959441632032394\nEpoch: 2, Batch: 170, Loss: 0.07879309356212616\nEpoch: 2, Batch: 180, Loss: 0.059489183127880096\nEpoch: 2, Batch: 190, Loss: 0.07463684678077698\nEpoch: 2, Batch: 200, Loss: 0.13005982339382172\nEpoch: 2, Batch: 210, Loss: 0.08769022673368454\nEpoch: 2, Batch: 220, Loss: 0.07310807704925537\nEpoch: 2, Batch: 230, Loss: 0.057187214493751526\nEpoch: 2, Batch: 240, Loss: 0.12339359521865845\nEpoch: 3, Batch: 0, Loss: 0.0437072291970253\nEpoch: 3, Batch: 10, Loss: 0.09855107963085175\nEpoch: 3, Batch: 20, Loss: 0.1054268330335617\nEpoch: 3, Batch: 30, Loss: 0.033250343054533005\nEpoch: 3, Batch: 40, Loss: 0.02991454117000103\nEpoch: 3, Batch: 50, Loss: 0.10166190564632416\nEpoch: 3, Batch: 60, Loss: 0.07871413975954056\nEpoch: 3, Batch: 70, Loss: 0.024368569254875183\nEpoch: 3, Batch: 80, Loss: 0.09798222035169601\nEpoch: 3, Batch: 90, Loss: 0.0372309610247612\nEpoch: 3, Batch: 100, Loss: 0.03466303274035454\nEpoch: 3, Batch: 110, Loss: 0.02023433893918991\nEpoch: 3, Batch: 120, Loss: 0.11005909740924835\nEpoch: 3, Batch: 130, Loss: 0.024488909170031548\nEpoch: 3, Batch: 140, Loss: 0.08485562354326248\nEpoch: 3, Batch: 150, Loss: 0.04444389417767525\nEpoch: 3, Batch: 160, Loss: 0.07943844795227051\nEpoch: 3, Batch: 170, Loss: 0.04078901559114456\nEpoch: 3, Batch: 180, Loss: 0.038149502128362656\nEpoch: 3, Batch: 190, Loss: 0.043284617364406586\nEpoch: 3, Batch: 200, Loss: 0.030403783544898033\nEpoch: 3, Batch: 210, Loss: 0.08526719361543655\nEpoch: 3, Batch: 220, Loss: 0.03183239325881004\nEpoch: 3, Batch: 230, Loss: 0.06705675274133682\nEpoch: 3, Batch: 240, Loss: 0.06075724586844444\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save_pretrained('model')\ntokenizer.save_pretrained('tokenizer')","metadata":{"execution":{"iopub.status.busy":"2024-06-20T18:49:43.615732Z","iopub.execute_input":"2024-06-20T18:49:43.616124Z","iopub.status.idle":"2024-06-20T18:49:56.241468Z","shell.execute_reply.started":"2024-06-20T18:49:43.616093Z","shell.execute_reply":"2024-06-20T18:49:56.240478Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'min_length': 8, 'num_beams': 2, 'no_repeat_ngram_size': 4}\n","output_type":"stream"},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"('tokenizer/tokenizer_config.json',\n 'tokenizer/special_tokens_map.json',\n 'tokenizer/spiece.model',\n 'tokenizer/added_tokens.json')"},"metadata":{}}]}]}
